{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Toch and check version\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D tensor\n",
    "\n",
    "a = torch.tensor([2, 2, 1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2D tensor\n",
    "\n",
    "b = torch.tensor([\n",
    "    [2, 1, 4],\n",
    "    [3, 5, 4],\n",
    "    [1, 2, 0],\n",
    "    [4, 3, 2]\n",
    "    ])\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making tensors withnon-integer real numbers\n",
    "# setting dtype = float or double\n",
    "c = torch.tensor([\n",
    "    [2, 1, 4],\n",
    "    [3, 5, 4],\n",
    "    [1, 2, 0],\n",
    "    [4, 3, 2]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "print(c, c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Play with shape and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size and shape of tensors\n",
    "\n",
    "print(\"Size and shape of a: \", a.size(), \" \", a.shape)\n",
    "print(\"Size and shape of b: \", b.size(), \" \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows and columns in a tensor\n",
    "\n",
    "print(\"Rows and columns of b: \", b.shape[0], \" \", b.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping array\n",
    "\n",
    "b1 = b.view(-1, 2)  # Auto infer row, col = 2\n",
    "print(\"b1(?, 2)\", b1)\n",
    "\n",
    "b2 = b.view(-1)  # Make no row, auto infer col \n",
    "print(\"b2(?)\", b2) \n",
    "\n",
    "b3 = b.view(1, -1)  # Make 1 row, auto infer col\n",
    "print(\"b3(1, ?)\", b3) \n",
    "\n",
    "b4 = b.view(-1, 1)  # Auto infer row, col = 1\n",
    "print(\"b4(?, 1)\", b4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make tensors of specific type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random 2D tensor\n",
    "\n",
    "r1 = torch.rand(3, 4)\n",
    "print(r1.dtype, r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random 2D tensor from a N(0,1)\n",
    "\n",
    "r2 = torch.rand(3, 4)\n",
    "print(r2.dtype, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random 3D tensor from a N(0,1)\n",
    "\n",
    "r3 = torch.rand(2, 3, 4)\n",
    "print(r3.dtype, r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create int array from a given range, of a given size\n",
    "\n",
    "i1 = torch.randint(6, 10, (5,))  # 10 is excluded\n",
    "print(i1.dtype, i1)\n",
    "\n",
    "i2 = torch.randint(6, 10, (2,3))\n",
    "print(i2.dtype, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Zeros matrix\n",
    "\n",
    "z = torch.zeros(2, 3)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Ones matrix\n",
    "\n",
    "o = torch.ones(2, 3)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor like the size of another tensor, of a give data type\n",
    "\n",
    "r2_la = torch.rand_like(r2, dtype=torch.double)\n",
    "print(r2_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Slicing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = torch.rand(3, 3)\n",
    "print(rs)\n",
    "\n",
    "# All row, col index 1\n",
    "rs1 = rs[:,1]\n",
    "print(rs1, rs1.shape)\n",
    "\n",
    "# All row, col index 1 while keeping the \"shape\"\n",
    "rs2 = rs[:,1:2]\n",
    "print(rs2, rs2.shape)\n",
    "\n",
    "\n",
    "# All col, row index 2\n",
    "print(rs[2,:])\n",
    "\n",
    "# Row index 1-2, col index 0-1\n",
    "print(rs[1:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extracting element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up a tensor element\n",
    "rs_tensor = rs[1,1]\n",
    "print(rs_tensor)\n",
    "\n",
    "# Extract number out of that tensor\n",
    "rs_number = rs_tensor.item()\n",
    "print(rs_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. NumPy - PyTorch - List interconversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list\n",
    "l_a = [1, 2, 3]\n",
    "l_b = [[1, 2], [3, 4]]\n",
    "\n",
    "print(l_a, type(l_a))\n",
    "print(l_b, type(l_b))\n",
    "\n",
    "# Convert list to tensor\n",
    "t_a = torch.tensor(l_a)\n",
    "t_b = torch.tensor(l_b)\n",
    "\n",
    "print(t_a, type(t_a))\n",
    "print(t_b, type(t_b))\n",
    "\n",
    "# Convert tensor to numpy\n",
    "n_a = t_a.numpy()\n",
    "n_b = t_b.numpy()\n",
    "\n",
    "print(n_a, type(n_a))\n",
    "print(n_b, type(n_b))\n",
    "\n",
    "# Convert numpy to tensor\n",
    "t2_a = torch.from_numpy(n_a)\n",
    "t2_b = torch.from_numpy(n_b)\n",
    "\n",
    "print(t2_a, type(t2_a))\n",
    "print(t2_b, type(t2_b))\n",
    "\n",
    "# Convert tensor to list\n",
    "l2_a = t2_a.tolist()\n",
    "l2_b = t2_b.tolist()\n",
    "\n",
    "print(l2_a, type(l2_a))\n",
    "print(l2_b, type(l2_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tensor concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row concatenation of tensors - concat alson dim 0\n",
    "# Size must match in all except dim 0\n",
    "\n",
    "ft1 = torch.randn(2, 5)\n",
    "ft2 = torch.randn(3, 5)\n",
    "\n",
    "print(\"IP tensor 1 \\n\", ft1)\n",
    "print(\"IP tensor 2 \\n\", ft2)\n",
    "\n",
    "fr = torch.cat([ft1, ft2])\n",
    "print(\"OP tensor \\n\", fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column concatenation of tensors - concat alson dim 1\n",
    "# Size must match in all except dim 1\n",
    "st1 = torch.randn(4, 3)\n",
    "st2 = torch.randn(4, 2)\n",
    "\n",
    "print(\"IP tensor 1 \\n\", st1)\n",
    "print(\"IP tensor 2 \\n\", st2)\n",
    "\n",
    "sr = torch.cat([st1, st2], 1)\n",
    "print(\"OP tensor \\n\", sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tensor dimension manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsqueeze tensor i.e. add 1 more dimension\n",
    "# within the range of current dimensions\n",
    "\n",
    "# 1D tensor\n",
    "t1 = torch.rand(3)\n",
    "print(t1, t1.shape)\n",
    "\n",
    "t1s0 = torch.unsqueeze(t1, 0)\n",
    "print(t1s0, t1s0.shape)\n",
    "\n",
    "t1s1 = torch.unsqueeze(t1, 1)\n",
    "print(t1s1, t1s1.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2D tensor\n",
    "t2 = torch.rand(2,3)\n",
    "print(t2, t2.shape)\n",
    "\n",
    "t2s0 = torch.unsqueeze(t2, 0)\n",
    "print(t2s0, t2s0.shape)\n",
    "\n",
    "t2s1 = torch.unsqueeze(t2, 1)\n",
    "print(t2s1, t2s1.shape)\n",
    "\n",
    "t2s2 = torch.unsqueeze(t2, 2)\n",
    "print(t2s2, t2s2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze tensor i.e. remove dimension of size 1\n",
    "# else leave it unchanged\n",
    "\n",
    "t2s1u = torch.squeeze(t2s1)\n",
    "print(t2s1u, t2s1u.shape)\n",
    "\n",
    "t2s1u0 = torch.squeeze(t2s1, 0)\n",
    "print(t2s1u0, t2s1u0.shape)\n",
    "\n",
    "t2s1u1 = torch.squeeze(t2s1, 1)\n",
    "print(t2s1u1, t2s1u1.shape)\n",
    "\n",
    "t2s1u2 = torch.squeeze(t2s1, 2)\n",
    "print(t2s1u2, t2s1u2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.]) None\n",
      "tensor(21.) None\n"
     ]
    }
   ],
   "source": [
    "# Without grad = True\n",
    "\n",
    "x1 = torch.tensor([1., 2., 3.])\n",
    "x2 = torch.tensor([4., 5., 6.])\n",
    "\n",
    "y = x1 + x2\n",
    "print(y, y.grad_fn)\n",
    "\n",
    "z = y.sum()\n",
    "print(z, z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>) <AddBackward0 object at 0x7f661cc2a6a0>\n",
      "tensor(21., grad_fn=<SumBackward0>) <SumBackward0 object at 0x7f661cc2a6a0>\n"
     ]
    }
   ],
   "source": [
    "# With grad = True on all inputs\n",
    "\n",
    "x1 = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "x2 = torch.tensor([4., 5., 6.], requires_grad=True)\n",
    "\n",
    "y = x1 + x2\n",
    "print(y, y.grad_fn)\n",
    "\n",
    "z = y.sum()\n",
    "print(z, z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>) <AddBackward0 object at 0x7f661cc2aee0>\n",
      "tensor(21., grad_fn=<SumBackward0>) <SumBackward0 object at 0x7f661cc2aee0>\n"
     ]
    }
   ],
   "source": [
    "# With grad = True, but not on all inputs\n",
    "\n",
    "x1 = torch.tensor([1., 2., 3.])\n",
    "x2 = torch.tensor([4., 5., 6.], requires_grad=True)\n",
    "\n",
    "y = x1 + x2\n",
    "print(y, y.grad_fn)\n",
    "\n",
    "z = y.sum()\n",
    "print(z, z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Autograd enabling and disabling\n",
    "\n",
    "x = torch.tensor([1., 2., 3.])\n",
    "print(x.requires_grad)\n",
    "\n",
    "x.requires_grad_()\n",
    "print(x.requires_grad)\n",
    "\n",
    "# Discarding history and grad functionality of a tensor into a new tensor\n",
    "\n",
    "x_det = x.detach()\n",
    "print(x_det.requires_grad)\n",
    "\n",
    "# Perform operation with autograd disabled\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Perform backward gradient calculation\n",
    "\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "z = 3 * y ** 2\n",
    "print(z)\n",
    "\n",
    "o = z.mean()\n",
    "print(o)\n",
    "\n",
    "o.backward()\n",
    "\n",
    "print(z.grad)\n",
    "print(y.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
